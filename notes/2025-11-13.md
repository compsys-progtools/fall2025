---
file_format: mystnb
kernelspec:
    name: python3
---



+++{"lesson_part": "main","type":"heading"}

# How to store a value 



+++{"lesson_part": "main"}


We need a few more components: 

- [mux](https://lodev.org/logicemu/#id=mux) select one of two values
- [flip-flop](https://lodev.org/logicemu/#) hold a value until told otherwise

::::::{important}
We spent time and walked through those two components to understand how they work
:::::::::


+++{"lesson_part": "main"}


[register](https://lodev.org/logicemu/#id=register)

::::::{exercise}
Use how the mux and flip-flop work to explain how the register works
:::::::::


+++{"lesson_part": "main"}


Registers give us SRAM which can hold a value as long as the system has power 


+++{"lesson_part": "main","type":"heading"}

## another way to physically store a value 


+++{"lesson_part": "main"}


DRAM uses one transistor and one capacitor. (SRAM uses 4-6 transistors)

a capacitor holds a charge for a time, but gradually fades, so it has to be refreshed



+++{"lesson_part": "main"}

ROM is a diode matrix traditionally
- hardward encodes the instructions
- cannot be changed without rewiring

+++{"lesson_part": "main"}

### PROM
- can be reprogrammed once after device is made
- used for firmware/microcode

(programmable ROM)

+++{"lesson_part": "main"}
### EPROM or EEPROM
- treated like ROM
- can be erased & reprogrammed
- but not infinitely, very limited number of tmes
- holds value when power goes away, UV light or electriciy can re-program
  

+++{"lesson_part": "main"}

### SRAM:

- is volatile; it needs power to hold a value
- is fast 
- takes up more space on the chip (uses 4-6 transistors per bit)
- typically used of cache and internal registers

+++{"lesson_part": "main"}
### DRAM: 
- is volatile;  it needs power to hold a value
- is slower and requires a refresh
- is small (1 transistor + 1 capacitor per bit) and space efficient
- used for the main RAM

+++{"lesson_part": "main"}

### Flash memory 
- non-volatile; holds a value without power, can be electircally erased and re-programmed
- comprised of memory "cells" in layerd boards
- memory cells are mosfets - a different type of transistor that retains a state after power is removed and put bag
- implemented with EEPROM 
- designed for large blocks and limited writes (~10k)
- used for ssd, usb flash drives, smartphones, etc
- slow to write, fast to read


## Why does this matter?

:::::{exercise}
:label: addspeed
which will be faster? 
```Python
5 + 7 +9 
``` 

```Python 
a = 5
b = 7 
c = 9
a+b+c 
```
::::::::



::::::::{solution}  addspeed
:class: dropdown

```{code-cell} ipython3
import timeit
from numpy import round

one_line = '5+7+9'
multi_line = """\
a = 5
b = 7 
c = 9
a+b+c 
"""

one_line_time = timeit.timeit(one_line,number=10000)
multi_line_time = timeit.timeit(multi_line,number=10000)
one_line_time, multi_line_time
```

From this, we see that {eval}`one_line_time` is smaller than {eval}`multi_line_time`; in fact it is {eval}`str(round(multi_line_time/one_line_time,2))`x faster to do the addition in 1 line without variables. 


We can even see that it takes more time to store the value to a variable than to only compute it:
```{code-cell} ipython3

one_line_store = 's=5+7+9'
one_line_store_time = timeit.timeit(one_line_store,number=10000)
one_line_store_time
```

{eval}`one_line_store_time` is just a little bit more than {eval}`one_line_time`, but it is still more. 

This is not to say that it is not good to create variables; readability of code also matters, but it is important to know what can speed things up.  Speeding things up can reduce electricity use of code and save money, but it can also cost more time if no one else can understand your code.  It's a tradeoff that you have to make as a developer. 
::::::::::::

:::::{exercise}
:label: ssdfaster
Would it be faster to: 
- read a whole file into memory, process, and write the results to a file once
- read in small chunks, process that chunk, write out the chunk
::::::::

:::::{solution} ssdfaster
:class: dropdown

Since reading ssd is fast, but writing is slow, the first one would be faster, as long as there was no parallelization and the processing was relatively fast. 

If you can process the chunks in parallel in the second case it could be faster if the processing was complex enough that it overtakes the time to write
::::::::::


::::{tip}
You can actually implement [the above](ssdfaster) and analyze data for an explore badge
:::::


## Prepare for Next Class 

```{include} ../_prepare/2025-11-18.md
```

## Badges

`````{tab-set}
````{tab-item} Review
```{include} ../_review/2025-11-13.md
```

````

````{tab-item} Practice
```{include} ../_practice/2025-11-13.md
```

````
`````



## Experience Report Evidence

## Questions After Today's Class 